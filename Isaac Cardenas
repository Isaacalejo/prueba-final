# -*- coding: utf-8 -*-
"""redN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Zd73CBeI7QRpswIShiSe0taUSWx4pErm
"""

import os
import numpy as np
from sklearn.metrics import accuracy_score
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical

from sklearn.metrics import confusion_matrix
import seaborn as sns



from sklearn.linear_model import LogisticRegression
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from sklearn.preprocessing import LabelEncoder

import matplotlib.pyplot as plt



# Ruta a la carpeta de entrenamiento y prueba
train_dir = "/content/drive/MyDrive/CarneDataset/train"
test_dir = "/content/drive/MyDrive/CarneDataset/test"

# Definir parámetros
image_size = (100, 100)
batch_size = 32
epochs = 12
num_classes = 8

# Generador de datos de entrenamiento
train_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='categorical')

# Generador de datos de prueba
test_datagen = ImageDataGenerator(rescale=1./255)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='categorical')

# Crear el modelo CNN
model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(num_classes, activation='softmax'))

# Compilar el modelo
model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# Entrenar el modelo
model.fit(train_generator, epochs=epochs)

# Evaluar el modelo en el conjunto de prueba
accuracy = model.evaluate(test_generator)[1]
print("Accuracy:", accuracy)

"""# Sección nueva"""

# Obtener las predicciones en los datos de entrenamiento
y_train_true_labels = train_generator.classes
y_train_pred = model.predict(train_generator)
y_train_pred_labels = np.argmax(y_train_pred, axis=1)

# Obtener la matriz de confusión del error en entrenamiento
cm_train = confusion_matrix(y_train_true_labels, y_train_pred_labels)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_train, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title("Matriz de Confusión - Entrenamiento")
plt.xlabel("Predicción")
plt.ylabel("Etiqueta Verdadera")
plt.show()

# Obtener las predicciones en los datos de prueba
y_test_true_labels = test_generator.classes
y_test_pred = model.predict(test_generator)
y_test_pred_labels = np.argmax(y_test_pred, axis=1)

# Obtener la matriz de confusión del error en prueba
cm_test = confusion_matrix(y_test_true_labels, y_test_pred_labels)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_test, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title("Matriz de Confusión - Prueba")
plt.xlabel("Predicción")
plt.ylabel("Etiqueta Verdadera")
plt.show()

# Obtener las predicciones en los datos de entrenamiento
y_train_pred_labels = np.argmax(model.predict(train_generator), axis=1)

# Obtener la matriz de confusión del modelo en entrenamiento
cm_train_model = confusion_matrix(y_train_true_labels, y_train_pred_labels)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_train_model, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title("Matriz de Confusión del Modelo - Entrenamiento")
plt.xlabel("Predicción")
plt.ylabel("Etiqueta Verdadera")
plt.show()

#SEGUNDO METODOS LINEAL


# Ruta a la carpeta de entrenamiento
train_dir = "/content/drive/MyDrive/CarneDataset/train"

# Definir parámetros
image_size = (100, 100)  # Reducción del tamaño de las imágenes

# Cargar y reducir las imágenes
X_train = []
y_train = []
for class_label in os.listdir(train_dir):
    class_dir = os.path.join(train_dir, class_label)
    for img_name in os.listdir(class_dir):
        img_path = os.path.join(class_dir, img_name)
        img = load_img(img_path, target_size=image_size)
        img_array = img_to_array(img)
        X_train.append(img_array)
        y_train.append(class_label)

X_train = np.array(X_train) / 255.0  # Normalización de los valores de píxel

# Codificar las etiquetas de clase a valores numéricos
label_encoder = LabelEncoder()
y_train_encoded = label_encoder.fit_transform(y_train)

# Obtener el número de clases
num_classes = len(label_encoder.classes_)

# Convertir las etiquetas codificadas a representación one-hot
y_train_categorical = to_categorical(y_train_encoded, num_classes)

# Aplanar las imágenes
X_train = X_train.reshape(X_train.shape[0], -1)

# Crear y entrenar el modelo lineal
model = LogisticRegression(max_iter=1000)
model.fit(X_train, np.argmax(y_train_categorical, axis=1))  # Convertir y_train_categorical a 1D

# Ruta a la carpeta de prueba
test_dir = "/content/drive/MyDrive/CarneDataset/test"

# Cargar y reducir las imágenes de prueba
X_test = []
y_test = []
for class_label in os.listdir(test_dir):
    class_dir = os.path.join(test_dir, class_label)
    for img_name in os.listdir(class_dir):
        img_path = os.path.join(class_dir, img_name)
        img = load_img(img_path, target_size=image_size)
        img_array = img_to_array(img)
        X_test.append(img_array)
        y_test.append(class_label)

X_test = np.array(X_test) / 255.0  # Normalización de los valores de píxel

# Codificar las etiquetas de clase de prueba
y_test_encoded = label_encoder.transform(y_test)
y_test_categorical = to_categorical(y_test_encoded, num_classes)

# Aplanar las imágenes de prueba
X_test = X_test.reshape(X_test.shape[0], -1)

# Realizar predicciones en los datos de prueba
y_pred = model.predict(X_test)
accuracy = accuracy_score(np.argmax(y_test_categorical, axis=1), y_pred)
print("Accuracy:", accuracy)




# Obtener las etiquetas predichas para los datos de entrenamiento
y_train_pred = model.predict(X_train)
train_cm = confusion_matrix(np.argmax(y_train_categorical, axis=1), y_train_pred)

# Obtener las etiquetas predichas para los datos de prueba
test_cm = confusion_matrix(np.argmax(y_test_categorical, axis=1), y_pred)

# Mostrar las matrices de confusión utilizando Seaborn
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
sns.heatmap(train_cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title("Confusion Matrix (Training)")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")

plt.subplot(1, 2, 2)
sns.heatmap(test_cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title("Confusion Matrix (Test)")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")

plt.tight_layout()
plt.show()
